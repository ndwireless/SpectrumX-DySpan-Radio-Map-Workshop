{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bce68a-7a03-4555-81c4-67b915258151",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In this notebook, we will process the radio maps from the previous notebook and prepare them for NN inference. First, we will use sensors to gather\n",
    "spectrum power measurements over the power maps. Then we will prepare the sensor measurements and power maps for neural network inference. This will \n",
    "include ensuring image resolution size is within the range of the neural network and applying the Log Likelihood Test for Occupancy.\n",
    "'''\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "'''\n",
    "3_CreatingTheDataset\n",
    "- Sensors\n",
    "- Subregion Pooling\n",
    "- Occupancy LLRT\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27538a8e-d556-4499-88db-204588b09431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_larger_sensors(sensor_map):\n",
    "    '''\n",
    "    This is a function we'll use to help us visualize the sensor locations\n",
    "    '''\n",
    "    max_x = sensor_map.size(dim=1)\n",
    "    max_y = sensor_map.size(dim=0)\n",
    "    out_sensor_map = torch.zeros(max_y, max_x)\n",
    "    for y in range(sensor_map.size(dim=0)):\n",
    "        for x in range(sensor_map.size(dim=1)):\n",
    "            if sensor_map[y, x]:\n",
    "                out_sensor_map[y, x] = 1\n",
    "\n",
    "                back_y = y - 1 >= 0\n",
    "                for_y = y + 1 < max_y\n",
    "\n",
    "                back_x = x - 1 >= 0\n",
    "                for_x = x + 1 < max_x\n",
    "\n",
    "                if back_y:\n",
    "                    out_sensor_map[y - 1, x] = 1\n",
    "\n",
    "                if back_x:\n",
    "                    out_sensor_map[y, x - 1] = 1\n",
    "\n",
    "                if for_y:\n",
    "                    out_sensor_map[y + 1, x] = 1\n",
    "\n",
    "                if for_x:\n",
    "                    out_sensor_map[y, x + 1] = 1\n",
    "    return out_sensor_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e05ef7-cc79-43ee-8885-0094c3438e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE POWER MAPS FROM NOTEBOOK 2\n",
    "power_maps_dBm = torch.load(\"power_maps.pt\")  # dBm\n",
    "threshold_dBm = -90\n",
    "num_maps = power_maps_dBm.size(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fbca57-a1c6-4c81-9aea-a5381794ade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PUTTING DOWN SPECTRUM SENSORS\n",
    "Here we'll emulate spectrum sensors across the power maps to generate sensor maps containing spectrum power measurements. There are multiple ways to \n",
    "estimate the spectrum power. For this tutorial, however, we'll assume the sensors measure the power exactly and simply measure the mean power of the\n",
    "subregion.\n",
    "'''\n",
    "# Change the number of sensors used per map by editing \"num_sensors_per_map\"\n",
    "num_sensors_per_map = 100\n",
    "sensor_locs = torch.zeros(*power_maps_dBm.shape)\n",
    "torch.manual_seed(423)\n",
    "\n",
    "# Generate random sensor locations using the randperm function\n",
    "for i_map in range(num_maps):\n",
    "    sensors = torch.randperm(512 * 512).reshape(512, 512) < num_sensors_per_map\n",
    "    sensor_locs[i_map] = sensors\n",
    "\n",
    "# Peek at the sensor locations for map 'i_map'. Black dots represent the sensor generated random sensor locations\n",
    "i_map = 9\n",
    "viz_sensor_locs = make_larger_sensors(make_larger_sensors(sensor_map=sensor_locs[i_map]))\n",
    "plt.imshow(-torch.flip(viz_sensor_locs, dims=[0]), vmin=-1, vmax=1, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(f'Sensor Locations for Map: {i_map}')\n",
    "plt.show()\n",
    "\n",
    "# Generate the sensor maps by sampling the power maps\n",
    "sensor_maps = power_maps_dBm * sensor_locs\n",
    "\n",
    "# Peek at sensor locations for map 'i_map'. Black dots are sensors seeing power below the threshold. White dots are sensors seeing power above the \n",
    "# threshold. NOTE: The sensors are measuring the power of the spectrum. We are just thresholding them for visualization sake. Notice that the white\n",
    "# sensor dots line up with where the occupancy circle is.\n",
    "viz_sensors_above_threshold = make_larger_sensors(make_larger_sensors(sensor_map=((sensor_maps[i_map] > threshold_dBm) * sensor_locs[i_map]).to(torch.float32)))\n",
    "viz_sensors_below_threshold = make_larger_sensors(make_larger_sensors(sensor_map=((sensor_maps[i_map] < threshold_dBm) * sensor_locs[i_map]).to(torch.float32)))\n",
    "\n",
    "shrink = 0.6\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axs[0].imshow(torch.flip(viz_sensors_above_threshold - viz_sensors_below_threshold, dims=[0]), vmin=-1, vmax=1, cmap='gray')\n",
    "axs[0].axis(\"off\")\n",
    "axs[0].set_title('Thresholded\\nSensor Measurements')\n",
    "\n",
    "im = axs[1].imshow(torch.flip(power_maps_dBm[i_map], dims=[0]))\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('Power Map [dBm]')\n",
    "plt.colorbar(im, ax=axs[1], shrink=shrink)\n",
    "\n",
    "occupancy_map = power_maps_dBm[i_map] > threshold_dBm\n",
    "axs[2].imshow(torch.flip(occupancy_map, dims=[0]), interpolation='nearest')\n",
    "axs[2].axis(\"off\")\n",
    "axs[2].set_title('Occupancy Map')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a9bd05-d35b-4fdb-9624-43fb90ee5a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "SUBREGION POOLING\n",
    "We implement subregion pooling to transform the 512x512 radio maps into 128x128 radio maps. To do this, we'll separate the 'full resolution' 512x512\n",
    "radio maps into non-overlapping 4x4 subregions and perform a pooling operation. We use two pooling operations for the radio maps: power pooling & sensor\n",
    "pooling. The power pooling is just an average pooling operation and we'll use PyTorch's built-in pooling function. The sensor pooling averages the power \n",
    "of all spectrum power measurements in a subregion.\n",
    "'''\n",
    "#  POWER MAP POOLING\n",
    "power_pooling_func = torch.nn.AvgPool2d(kernel_size=4, padding=0, stride=4)  # Initialize PyTorch's built-in Mean Pooling function\n",
    "pooled_power_maps_dBm = power_pooling_func(10**(power_maps_dBm/10))  # Need to average in mW\n",
    "pooled_power_maps_dBm = 10 * torch.log10(pooled_power_maps_dBm) # Convert the pooled power maps to log domain [dBm]\n",
    "print(f'Full-Res Power Maps Shape: {power_maps_dBm.shape}, Pooled Power Maps Shape: {pooled_power_maps_dBm.shape}')\n",
    "\n",
    "# Generate pooled sensor map\n",
    "def sensor_pool(sensor_maps, kernel_size=4):\n",
    "    '''\n",
    "    This function is similar to Avg2DPool, but instead of averaging every value in a kernel, it only averages the non-zero values. This allows it to\n",
    "    average all the sensor measurements in a subregion.\n",
    "    '''\n",
    "    num_maps, ysize, xsize = sensor_maps.shape\n",
    "    pooled_sensor_map = torch.zeros(num_maps, ysize // kernel_size, xsize // kernel_size)\n",
    "    for i_map in range(num_maps):\n",
    "        for iypool in range(ysize // kernel_size):\n",
    "            for ixpool in range(xsize // kernel_size):\n",
    "                subregion = sensor_maps[i_map, kernel_size*iypool:kernel_size*(iypool+1), kernel_size*ixpool:kernel_size*(ixpool+1)].clone() # Grab subregion\n",
    "                num_sensors_in_subregion = torch.count_nonzero(subregion) # Count the number of sensors in the subregion\n",
    "                if num_sensors_in_subregion: # If there are sensors in the subregion\n",
    "                    subregion[subregion != 0] = 10 ** (subregion[subregion != 0] / 10) # Convert subregion sensor values to mW\n",
    "                    pooled_sensor_map[i_map, iypool, ixpool] = torch.sum(subregion) / num_sensors_in_subregion # Average the sensor measurements\n",
    "                    pooled_sensor_map[i_map, iypool, ixpool] = 10 * torch.log10(pooled_sensor_map[i_map, iypool, ixpool]) # Convert back to dBm\n",
    "\n",
    "    return pooled_sensor_map\n",
    "\n",
    "pooled_sensor_maps = sensor_pool(sensor_maps=sensor_maps, kernel_size=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8157413-705f-4956-964a-24f1619546d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  PEEK AT THE POOLED POWER AND SENSOR MAPS\n",
    "#  Choose which power map and sensor map pair to viz by editing \"i_map\"\n",
    "i_map = 2\n",
    "\n",
    "#  POOLED POWER MAP PEEK\n",
    "vmin = min([power_maps_dBm[i_map].min(), pooled_power_maps_dBm[i_map].min()])\n",
    "vmax = max([power_maps_dBm[i_map].max(), pooled_power_maps_dBm[i_map].max()])\n",
    "shrink = 0.48\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "im = axs[0].imshow(torch.flip(power_maps_dBm[i_map], dims=[0]), vmin=vmin, vmax=vmax)\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title('Full-Res Power Map [dBm]')\n",
    "plt.colorbar(im, ax=axs[0], shrink=shrink)\n",
    "\n",
    "im = axs[1].imshow(torch.flip(pooled_power_maps_dBm[i_map], dims=[0]), vmin=vmin, vmax=vmax)\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('Pooled Power Map [dBm]')\n",
    "plt.colorbar(im, ax=axs[1], shrink=shrink)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#  POOLED SENSOR MAP PEEK\n",
    "viz_sensors_above_threshold = make_larger_sensors(make_larger_sensors(sensor_map=((sensor_maps[i_map] > threshold_dBm) * sensor_locs[i_map]).to(torch.float32)))\n",
    "viz_sensors_below_threshold = make_larger_sensors(make_larger_sensors(sensor_map=((sensor_maps[i_map] < threshold_dBm) * sensor_locs[i_map]).to(torch.float32)))\n",
    "\n",
    "pooled_viz_sensors_above_threshold = ((pooled_sensor_maps[i_map] > threshold_dBm) * (pooled_sensor_maps[i_map] != 0)).to(torch.float32)\n",
    "pooled_viz_sensors_below_threshold = ((pooled_sensor_maps[i_map] < threshold_dBm) * (pooled_sensor_maps[i_map] != 0)).to(torch.float32)\n",
    "\n",
    "print(f'Full-Res Sensor Maps Shape: {sensor_maps.shape}, Pooled Sensor Maps Shape: {pooled_sensor_maps.shape}')\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(torch.flip(viz_sensors_above_threshold - viz_sensors_below_threshold, dims=[0]), vmin=-1, vmax=1, cmap='gray')\n",
    "axs[0].axis(\"off\")\n",
    "axs[0].set_title('Sensor Measurements')\n",
    "\n",
    "axs[1].imshow(torch.flip(pooled_viz_sensors_above_threshold - pooled_viz_sensors_below_threshold, dims=[0]), vmin=-1, vmax=1, cmap='gray')\n",
    "axs[1].axis(\"off\")\n",
    "axs[1].set_title('Pooled Sensor Measurements')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caa8241-11e6-4534-b91b-22ed65555d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "GENERATE THE GROUND TRUTH POOLED OCCUPANCY MAPS THAT THE NEURAL NETWORK IS TRYING TO ESTIMATE\n",
    "'''\n",
    "pooled_occupancy_maps = (pooled_power_maps_dBm > threshold_dBm)\n",
    "\n",
    "# Peek the pooled occupancy maps and compare to the pooled power maps\n",
    "i_map = 2\n",
    "vmin = min([power_maps_dBm[i_map].min(), pooled_power_maps_dBm[i_map].min()])\n",
    "vmax = max([power_maps_dBm[i_map].max(), pooled_power_maps_dBm[i_map].max()])\n",
    "shrink = 0.48\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(torch.flip(pooled_occupancy_maps[i_map], dims=[0]), vmin=0, vmax=1, interpolation='nearest')\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title('Pooled Occupancy Maps')\n",
    "\n",
    "im = axs[1].imshow(torch.flip(pooled_power_maps_dBm[i_map], dims=[0]), vmin=vmin, vmax=vmax)\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('Pooled Power Maps [dBm]')\n",
    "plt.colorbar(im, ax=axs[1], shrink=shrink)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6061344-329f-46ba-9e7c-f7614ea23841",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "LOG LIKELIHOOD RATIO TEST FOR SPECTRUM OCCUPANCY\n",
    "Lastly, we treat the spectrum occupancy mapping problem as a detection problem where we are trying to decide between two hypotheses:\n",
    "H0: Unoccupied, or the average spectrum power in the subregion is below the threshold\n",
    "H1: Occupied, or the average spectrum power in a subregion is equal to or greater than the threshold\n",
    "\n",
    "The spectrum power sensors measure a power value close to the average power in the subregion they are in. To model this, we say the spectrum power\n",
    "measurement, m(s) is: m(s) = <f(r)G> + z(s) where \n",
    "- <f(r)G> is the average spectrum power in a subregion\n",
    "- z(s) is the error in representing the <f(r)G> by a sensor measurement. This is modeled as a Gaussian r.v.\n",
    "\n",
    "Now, we wish to determine whether H0: <f(r)G> < threshold or H1: <f(r)G> >= threshold\n",
    "We derive the simplified LLR(s) = m(s) - threshold\n",
    "\n",
    "Finally, we apply the LLR(s) to the sensor measurements. This creates the pooled llr sensor maps that the neural network performs inference over.\n",
    "\n",
    "NOTE: Applying LLR(s) to each sensor individually and sensor pooling the LLR values is equivalent to pooling the sensor power values and then\n",
    "applying the LLR to the pooled sensor maps to subregions that contained sensors.\n",
    "'''\n",
    "threshold_dBm = -90\n",
    "threshold_mW = 10**(threshold_dBm / 10)\n",
    "\n",
    "num_maps, ysize, xsize = pooled_sensor_maps.shape\n",
    "\n",
    "pooled_llr_sensor_maps = torch.zeros(num_maps, ysize, xsize)\n",
    "for i_map in range(num_maps):\n",
    "    for iypool in range(ysize):\n",
    "        for ixpool in range(xsize):\n",
    "            if pooled_sensor_maps[i_map, iypool, ixpool]:  # If the subregion contained a sensor (and thus contains a nonzero value)\n",
    "                mean_sensor_power = 10**(pooled_sensor_maps[i_map, iypool, ixpool] / 10) # Convert the sensor measurement to mW\n",
    "                pooled_llr_sensor_maps[i_map, iypool, ixpool] = (mean_sensor_power - threshold_mW) * 1e-3 # Apply the LLR in Watts (instead of mW)\n",
    "\n",
    "# For neural network stability, we also normalize each input map to unit variance\n",
    "for i_map in range(num_maps):\n",
    "    pooled_llr_sensor_maps[i_map] /= (pooled_llr_sensor_maps[i_map]).std()\n",
    "\n",
    "# Peek the pooled llr sensor maps and ensure it matches the pooled sensor maps\n",
    "i_map = 2\n",
    "pooled_viz_llr_sensors_H1 = (pooled_llr_sensor_maps[i_map] > 0).to(torch.float32)\n",
    "pooled_viz_llr_sensors_H0 = (pooled_llr_sensor_maps[i_map] < 0).to(torch.float32)\n",
    "pooled_viz_sensors_above_threshold = ((pooled_sensor_maps[i_map] > threshold_dBm) * (pooled_sensor_maps[i_map] != 0)).to(torch.float32)\n",
    "pooled_viz_sensors_below_threshold = ((pooled_sensor_maps[i_map] < threshold_dBm) * (pooled_sensor_maps[i_map] != 0)).to(torch.float32)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(torch.flip(pooled_viz_llr_sensors_H1 - pooled_viz_llr_sensors_H0, dims=[0]), vmin=-1, vmax=1, cmap='gray')\n",
    "axs[0].axis(\"off\")\n",
    "axs[0].set_title('Pooled LLR Sensor Measurements')\n",
    "\n",
    "axs[1].imshow(torch.flip(pooled_viz_sensors_above_threshold - pooled_viz_sensors_below_threshold, dims=[0]), vmin=-1, vmax=1, cmap='gray')\n",
    "axs[1].axis(\"off\")\n",
    "axs[1].set_title('Pooled Sensor Measurements')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607d6d3a-20a3-49c8-8c46-ebb60e7f6cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "SAVE THE POOLED OCCUPANCY MAPS AND POOLED LLR SENSOR MAPS FOR NEURAL NETWORK INFERENCE\n",
    "'''\n",
    "import os\n",
    "torch.save(pooled_occupancy_maps, f'{os.getcwd()}/pooled_occupancy_maps.pt')\n",
    "torch.save(pooled_llr_sensor_maps, f'{os.getcwd()}/pooled_llr_sensor_maps.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de5c7ce-34a8-4d3c-8461-b6db211096d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
